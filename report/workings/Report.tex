\documentclass[11pt,twoside,a4paper]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{float}
\usepackage[parfill]{parskip}
\usepackage{listings}


\begin{document}
\lstset{
   basicstyle=\fontsize{8}{9}\selectfont\ttfamily}
\setcounter{secnumdepth}{4}
\title{M4R}
\date{March 2nd, 2019}
\author{Anthony Webster CID 01051827}
\maketitle

\tableofcontents

\section{Introduction}
The steady Navier-Stokes equations govern steady state fluid interactions. These may arise due to lack of significant temporal changes of a system or at very long timescales where such changes fade out.\\
We seek to create an efficient solver of the steady Navier-Stokes equations in an arbitrary domain.
For this the Finite Element method is particularly suited, however the standard CG method can be inefficient and is not globally divergence free.\\
Using the $H_{div}$ space we get the global divergence free property. Additionally this allows us to use [2] and [9], which should give us an efficient and stable algorithm for solving whithin this space using the grad-div stabilization method.\\
The steady Navier-Stokes equation are as follows :
\begin{align}
(u \cdot \nabla) u &= -\nabla p + \mu \nabla^2 u + F \\
\nabla \cdot u &= 0
\end{align}
Note that from working in the $H_{div}$ space the second equation is naturally satisfied globally.
\\
First we will describe the classic Finite Element Method, its advantages and disadvantages, hence explaining why we are using a modified method. Secondly we will explain a number of definitions and tools used in the project and which may be unfamiliar to some readers. Then we will show how to find the weak form of the equations and build different parts of our solvers. Lastly we will consider some example cases and deduce that the algorithm converges to the right result at satisfactory rates.\\

\section{Tools and Definitions}
A number of well-known methods, algorithms and definitions are used in this report. This section serves to quickly introduce these concepts for latter use in our work.
\subsection{Classic Finite Elements Method}
The Finite Element Method (FEM) is a numerical method which approximates the solution to an exact partial differential equation [5]. The property that it works on arbitrary domains, as opposed to the finite difference method which finds the exact solution to an approximated discretized partial differential equation, is one of the reasons it is widely used in research, industry and in this project.\\
We will now consider the case of applying the FEM to the stokes equations using the more classic Lagrange finite element. We do this to explain how conventionally this problem would have been solved, and how our method will improve on it.\\
This method in particular is very common in research and industrial problems as such there are number of courses and books on the subject, such as \textit{Galerkin finite element methods for parabolic problems} if further explanation and theory is required.\\
\\
The Stokes equation is :
\begin{align}
0 &= -\nabla p + \mu \nabla^2 u + F \\
\nabla \cdot u &= 0
\end{align}
As seen in Common and Unusual Finite Elements [7], the Lagrange finite element approximates a function on a cell using polynomials of degree $q$ defined by their pointwise values at an array of points. Maximal global continuity is kept by making sure  that multiple cells agree on their respective edges.\\
For instance let us approximate $f = sin(x)$ from $0$ to $2 \pi$ using 1D first order Lagrange finite elements. We approximate the function on each of the four cells by a linear function. This linear function is defined on each cell using two points in it, the two edge points. Hence we get figure 1, where the blue curve indicates our approximation and the red one the exact function. In practice one can consider $f$ to be the sum of these linear functions. Note that this element is continuous across the "edges" of a cell, since regardless of cell the value of the interpolated function at the "edge" will be identical. This concept can be extended to 2D.\\
\begin{figure}
  \includegraphics[width=\linewidth]{ex_1D_LG.png}
  \caption{4 Element First Order Interpolation Example and Comparison to True Solution}
\end{figure}
\\
It follows that we first cut up our domain into a mesh. Commonly these meshes are made up of triangles for simplicity, although squares or even curved elements for simulations on a sphere are also used. Then we approximate $u$ and $p$ using the Lagrange element. Hence we get that for instance $u$ is the sum of a set of known piecewise linear functions (as they are determined by the mesh) but with unknown coefficients. The aim of the rest of the method is to determine these unknown coefficients.\\
For that end we need to find what is called the weak form of the equation. We multiply (3) by an arbitrary function $v$. Hence we get :
\begin{align*}
\int_{\omega} -v \cdot \nabla p + \mu v \cdot \nabla^2 u dx = -\int_{\omega} v \cdot F dx
\end{align*}
Since our domain $\omega$ is cut out into triangles we can cut the integral into triangles and work on each one individually. Hence for each cell $e$ in $\omega$ we get :
\begin{align*}
\int_{e} p \nabla \cdot v + \mu v \cdot \nabla^2 u dx =  -\int_{e} v \cdot F dx
\end{align*}
However since $u$ and $v$ will be approximated by functions which may be discontinuous in their derivatives $\nabla^2$ may not be defined. Hence we need to use integration by parts to get :
\begin{align*}
\int_{e} p \nabla \cdot v - \mu \nabla v \cdot \nabla u dx = -\int_{e} v \cdot F dx
\end{align*}
Finally multiplying (4) by a similar pressure test function $q$ and adding it to the left hand side of the above we get :
\begin{align}
\int_{e} p \nabla \cdot v - \mu \nabla v \cdot \nabla u dx + \int_{e} q \nabla \cdot u dx = -\int_{e} v \cdot F dx
\end{align}
Now we use the fact that $q$, $v$, $F$, $u$ and $p$ are a sum of known linear functions and coefficients.\\
Pulling out and removing the coefficients of $v$ we get that :
\begin{align*}
 \int_{e} \sum_i \sum_j (  p_j \phi_j \nabla  \cdot \Phi_i - \mu \nabla \Phi_i \cdot u_j \nabla \Phi_j +   \phi_i u_j \nabla \Phi_j) dx = -\int_{e} \sum_i \phi_i F_i \phi_i dx
\end{align*}
Combining all the triangles we can eventually turn our problem into a matrix equation of the form :
\begin{align}
M x = b
\end{align}
Where $x$ is a vector of coefficients of $u$ and $p$.\\
We can solve this using a variety of linear systems solvers. Note in particular that since the majority of basis functions $\Phi$ and $\phi$ are $0$ in any given triangle the matrix $M$ will be sparse.\\
While we locally enforced the divergence-free equation by including it in the weak form, the global flow may not be divergence-free. In order to achieve that more complex mathematical tools would be required.\\
Now apply this to the manufactured solution :
\begin{align*}
u_x &=  -sin(2 \pi y) cos(2 \pi y)  sin(2 \pi x)^2 \\
u_y &= sin(2 \pi x) cos(2 \pi x)  sin(2 \pi y)^2 \\
p &= sin(2 \pi x) sin(2 \pi y) \\
F &= \nabla p - \mu \nabla^2 u
\end{align*}
Where $F$ was selected specifically to ensure that any given $u$ and $p$ are solutions.
Using the above and implementing a solver using CG2 and CG1 in firedrake we get figures. On a mesh with 32 vertices we get an error of .\\
However default implementation using the CG method is slow, hence we wish to improve on it.

\subsection{BDM-DG Mixed Space}
Let us introduce the mixed space we will be working in for the rest of the paper. We will first define Brezzi-Douglas-Marini and explain the restrictions that come with it, then the discontinuous Galerkin and how combined with the BDM space we have an $H_{div}$ space.\\
\\
The paper Common and Unusual Finite Elements [7] states that the BDM space on one triangle $K$ is composed by polynomials of order $q$ defined by the normal component on each edge. If $q > 1$ it is also defined using the integration against gradients of the polynomials on the triangle. If $q > 2$ we then also use the integration  against curls of $b_K P_{q-2}(K)$ where $b_{q-2}$ is the cubic bubble function associated with $K$ and $P_{q}(K)$ is the set of polynomials defined on $K$.\\

However unlike the Lagrange elements we can no longer set a Dirichelet boundary condition's tangential component. Therefore we need to find alternative approaches to enforce these conditions.
Additionally some operations (such as the weak form of the curl) are undefined in this space. Due to possible discontinuities at the boundaries we have to be careful with all boundary integrals.
In general the weak form will be far more involved.\\
\\

The discontinuous Galerkin Element space is the space of piecewise linear discontinuous functions. An example applying this space on its own can be found in [8].\\
This finite element, combined with the BDM element for velocity, discretizes the function space $H_{div}$. A property we thus get from simply working in BDM is that our solution will be exactly divergence free globally and locally.
Additionally we will be able to employ an enhanced Lagrangian preconditioner thanks to the global divergence free property [2].\\

\subsection{Newton's Method}
The Navier-Stokes equations have a non-linear part in the advection term for the velocity component. Hence we will need an algorithm to solve such equations. As discussed in the Classic Finite Element section we will obtain a matrix equation. Therefore we will consider the Newton's method applied to an arbitrary matrix equation.\\
\\
Consider a non-linear equation of the form :
$$
F(x,y) = 0
$$
Where $F$ is a vector function and $x$ is vector of unknowns. Note that $F$ may be non-linear and have constant components.
For instance we could have $ F = x^T A x + M x - b$, where A and M are constant matrices and b is a constant vector.\\
We start with a guess $x = x_0$ and then determine the Jacobian of $F(x)$, call it $DF(x)$.\\
We determine the Jacobian by calculating the Gateaux derivative, defined as follows [12] :
\begin{align}
DF_{x_n}(\Delta x) = lim_{t \rightarrow 0^+} \frac{F(x_n+ \epsilon \Delta x) - F(x_n)}{\epsilon}
\end{align}
We then use the vector Taylor expansion :
\begin{align*}
F(x_{n+1}) = F(x_n) + DF_{x_n}(\Delta x) \Delta x
\end{align*}
Hence we get the algorithm :
\begin{align}
DF_{x_n}(\Delta x) \Delta x = - F(x_n)\\
x_{n+1} = x_n + \Delta x
\end{align}
We solve for $\Delta x$ using $x_n$ and the Taylor expansion approximation and then use this result to determine $x_{n+1}$.
This is a linear problem which can be solved via an LU Factorization for instance.\\
Note that the Newton's method only converges and is unique if it is within a ball around the solution [10-11]. Other methods may be required to get to that point.

\subsection{Preconditioners}
Computational cost of an algorithm is an important limitation which we want to limit as much as possible. This is especially true given that many experimental and industrial applications will require very high resolution to take into account the complex shapes and boundary layers involved. As such we utilized a Schur Preconditioner to keep the computational costs down. This section will introduce the general concept of Preconditioners.\\
\\
We will first describe how preconditioners, such as the Schur Preconditioner work in general. We see this in the book Multilevel Block Factorization Preconditioners [4] on pages 49 to 51.\\
Take the system :\\
$$
Mx = b
$$
Where $M$ is a very large matrix, assumed for simplicity to be symmetric, $x$ an unknown vector we need to solve for (in our case this will be a vector of coefficients for both $u$ and $p$) and $b$ a constant vector(containing forcing and boundary conditions for our problem). If $M$ is a symmetric positive definite sparse matrix then $M$ applied to a vector is cheap to compute. Hence we can easily find $r$ the residual :\\
$$
r = b - Mx
$$
We then use the resulting $r$ in order to provide a correction on our result.\\
However $M$ may not be well-behaved. In fact in our problem we know it is usually not due it being an elliptic problem.\\
In this case we use a preconditioning matrix, $P$ to map the system in such a way that $P^{-1}$ is cheap to compute, this operation can easily be parallelized and the condition number, the ratio of largest and smallest eigenvalue which describes the behavior of the system [13], is lowered (usually this implies better numerical behaviour).\\
We then numerically solve the transformed and hopefully better behaved system :
$$
P^{-1}(Mx-b) = 0
$$
This procedure allows us to transform a computationally ill-behaved matrix equation to an easier one.

\subsection{Notation}
Various notations are used throughout this paper. Although they are fairly common amongst papers in the subject we will re-introduce them here. Additionally this will allow us to explain some concepts which may not be familiar readers unfamiliar with discontinuous finite elements.\\
\\
Let us define $a_+$ and $a_-$.\\
When the mesh is setup the software ensures each facet (ie. edge of a triangle) in the mesh has a positive and negative side, and each cell agrees on which is which. We call this term on facet integrals, as otherwise it has no meaning. Then $a_+$ is the value of $a$ on the positive side $a_-$ on the negative side. The normal usually points from the negative to the positive side. However, when we consider for instance $(n \cdot a)_+$ we consider the whole expression on the "positive side" including the normal, which, with respect to any given cell, always points out of the cell, and hence may point in the opposite direction of the standard normal of the facet.\\
It is important to note that the positive and negative side are completely arbitrary. They serve as markers for the software. Obviously these terms do not appear in the continuous finite element spaces.\\
For facet which are facing the exterior domain we usually consider the equations separately.\\
\\
Let $\{ a \} = a_+ + a_-$. \\
This is an average term. Due to discontinuities of our space on facet elements integrals over facets from integration by parts on an individual element will not disappear necessarily, hence these terms remain. Additionally, since we cannot use Dirichelet boundary conditions, weak penalty terms will also use this operation.\\
For integrals over outer facet we explicitly write out the formula for clarity.\\
\\
Let $J(a) = a_+ - a_-$\\
This is a jump term. Note that this operation is $0$ in continuous space, which is where we assume the physical fluid velocity and pressure to be.\\
\\
We may have surface integrals over interior facet and exterior facet, which are on the computational boundaries.\\
In the first case the integral of $a$ is $\int_\Gamma a dS$ while in the latter we note $\int_{\delta \Omega} a ds$.\\
This is used both for additional clarity and because it is the notation in the code.\\
\\
sgn(k) is the sign of scalar k.

\section{$H_{div}$ Solver}
This section will explain the solver setup of the Navier-Stokes Equation. First we will deal with discretizing the steady Stokes equation, which is linear and explain how to implement a Schur Complement to improve performance. Then we will move on to the steady Navier-Stokes, first finding the weak form of the advection before introducing the continuation method. Lastly we will discuss a time stepping solver for the unsteady Navier-Stokes in order to study stability of solutions obtained from prior methods.
\subsection{Steady Stokes}
The linear nature of the Stokes equation makes it easier to solve, hence we considered it first.\\
The steady Stokes equation is, in it's standard strong form :
\begin{align}
0 &= -\nabla p + \mu \nabla^2 u + F  \\
\nabla \cdot u &= 0
\end{align}

\subsubsection{Weak Stokes Equation}
In this section we aim to find the weak form of the steady stokes equation, required for building the matrix system as seen in the classic FEM.\\
We start off by cutting our computational domain $\Omega$ into a set of cells $e$. As discussed above it is now required to find the weak form of equations (9) and (10) in the BDM/DG space.
For this purpose let us introduce two test functions, $w$ in BDM for velocity and $q$ in DG for pressure.
Let us multiply equation (9) by $v$ and integrate over the domain as seen in the first section.
\begin{align*}
\int_\Omega v \cdot F dx &= \int_\Omega (v \cdot \nabla p) dx - \int_\Omega (\mu v \cdot \nabla^2 u) dx
\end{align*}

Again we can work on each cell $e$ individually and them sum it all up, hence get :
\begin{align*}
\sum_e \int_e v \cdot F dx &= \sum_e (\int_e (v \cdot \nabla p) dx - \int_e (\mu v \cdot \nabla^2 u) dx)
\end{align*}
Focusing on the viscosity, or second, term we get via integration by parts :
\begin{align*}
\int_e (v \cdot \nabla^2 u) dx = - \int_e \nabla_h(v) : \nabla_h(u) dx + \int_\Gamma 2 \{ v_i n_j \} \{ \frac{\partial u_i}{\partial x_j}\} dS
\end{align*}
The first term can be summed up to an integral over $\Omega$ and the second one is asymmetrical. We can add a term to make it symmetrical. This helps with numerical stability of the final matrix equation. Numerical stability ensures that if there are errors in the input values of the problem (such as the exact values of an inflow), they lessen as the algorithm progresses. This property is obviously desirable especially when considering experimental information. Most measurement devices have a certain tolerance below which the measured value is uncertain. Additionally some linear solvers take advantage of this structure.\\
Hence this term becomes :
\begin{align*}
-  \int_\Omega \nabla_h(v) : \nabla_h(u) dx + \sum_e( \int_\Gamma 2 \{ v_i n_j \} \{ \frac{\partial u_i}{\partial x_j}\} dS + \int_\Gamma 2 \{ u_i n_j \} \{ \frac{\partial v_i}{\partial x_j}\} dS)
\end{align*}
Our physical velocity field is presumably continuous.
So $u$ should be continuous in the physical space thus the added term will be $0$ in continuous space. Hence this does not change the equation in physical space as added terms amount to $0$ physically.\\
\\
Now we also add the term $\alpha \int_\Gamma \frac{1}{h}  J(v_i) J(u_i) dS$. According to sources [3] and testing provided that  $\alpha$ is larger than $10$ numerical stability is increased.
($J$ is the jump notation).\\
The numerical value of $h$ is the average distance of a side. In our case we defined it as the average cell-volume over the length of the facets between them for each individual facet element $\Gamma$.\\
Again, any flow studied with this algorithm will have a continuous velocity and pressure fields. The $J(u_i)$ term makes this integral $0$ in continuous space so this does not change the solution.\\
\\
As mentioned in the BDM definition section we cannot set the tangential component of a Dirichelet boundary condition in the conventional finite element manner.  So instead we use penalty terms. These push the solution towards respecting the boundary conditions. In practice this just means taking all the terms over the edge of a cell and considering them on the sections of the edge of the domain where Dirichelet conditions apply instead.\\
 Hence our final viscous term becomes :\\
\begin{align*}
&-  \int_\Omega \nabla_h(v) : \nabla_h(u) dx + \sum_e ( \int_\Gamma 2 \{ v_i n_j \} \{ \frac{\partial u_i}{\partial x_j}\} dS + \int_\Gamma 2 \{ u_i n_j \} \{ \frac{\partial v_i}{\partial x_j}\} dS \\
&- \alpha \int_\Gamma \frac{1}{h}  J(v_i) J(u_i) dS \ ) + \int_{\partial  \Omega} v_i n_j \frac{\partial(u_i + u^0_i)}{\partial x_j} + (u_i + u^0_i) n_j\frac{\partial v_i}{\partial x_j} ds - \alpha \int_{\partial \Omega} \frac{1}{h} v_i(u_i-u^0_i)ds
\end{align*}
Where $u^0_i$ are the boundary values.
We will call this term $\eta_\mu$ for ease of writing. The firedrake coding structure allows us to practically write out the equation above as seen in the appendix.\\
Back to our original equation we get :
\begin{align}
\int_\Omega v \cdot F dx &= \int_\Omega v \cdot \nabla p dx - \eta_\mu
\end{align}
Let us consider the continuity equation again :
\begin{align*}
\nabla \cdot u = 0
\end{align*}
Multiplying by $q$ and integrating we get :
\begin{align*}
\int_\Omega q \nabla \cdot u dx = 0
\end{align*}
This is $0$, so we add this to the weak formulation $(3)$ we obtained, getting one weak formulation which includes both pressure and velocity while also keeping symmetry. As seen in the appendix this is required to the usage of a mixed space in ufl.\\
We need this since we want to turn the entire system into a single matrix equation which includes all the conditions.\\
Integrating by parts the pressure term get :
\begin{align}
\int_\Omega v \cdot F dx &= \int_\Omega p \ v \cdot n ds - \int_\Omega  p ( \nabla \cdot v) dx + \int_\Omega q (\nabla \cdot u) dx  - \eta_\mu
\end{align}
But v is $0$ on all the boundaries, hence get :
\begin{align}
\int_\Omega v \cdot F dx &= - \int_\Omega  p ( \nabla \cdot v) dx + \int_\Omega q (\nabla \cdot u) dx  - \eta_\mu
\end{align}

\subsubsection{Schur Preconditioner}
In an effort to get our iteration count to be independent of mesh-size, we will apply a Schur preconditioner similarly described in chapter 3 of Multilevel Block Factorization Preconditioners [4] as well as in source [2]. This will dramatically reduce the computational cost of the solver.\\
This is a well-known method, however as we will be modifying it, we will quickly describe it as well.
Our system effectively amounts to solving a matrix equation of the form :
$$
\begin{bmatrix}
A         & B^{T}\\
B         & 0 \\
\end{bmatrix}
\begin{bmatrix}
u    \\
p     \\
\end{bmatrix}
=
\begin{bmatrix}
b    \\
0     \\
\end{bmatrix}
$$
Where $B$ is the discretized divergence operator and $B^T$ the discrete gradient operator. $A$ contains the viscous term.
Setting $S = - B A^{-1} B^{T}$, we can factorize the above and get an expression whose inverse is :
$$
\begin{bmatrix}
I         & - A^{-1} B^{T}\\
0         & I \\
\end{bmatrix}
\begin{bmatrix}
A^{-1}   & 0\\
0       & S^{-1} \\
\end{bmatrix}
\begin{bmatrix}
I & 0\\
 - B A^{-1}       & I \\
\end{bmatrix}
$$
Hence, if we can find $A^{-1}$ and $S^{-1}$ we can easily solve the equation. We solve both via a Lu factorization.\\
We solve for $A^{-1}$, or to be exact the operation $A^{-1}v$ via an Lu Factorization. The Lu factorization is a direct solver, and thus is inefficient. The algorithm would have to be performed in a sequential manner, preventing usage of parallelization. We did mitigate this through the usage of the "mumps" sub-routine. We originally attempted to use ILU, which is more efficient, but this failed. This is because the viscous term makes a less sparse matrix.\\
 However $S^{-1}$, the inverse of the Schur complement is difficult to determine because it is usually dense. However research has shown [2 \& 9] that we can solve this issue by using a "grad-div" stabilization method. We add the term $\gamma \nabla \cdot v \: \nabla \cdot w$ to the equation (14). Note that this term is 0 in continuous space. We thus get :
\begin{align}
\int_\Omega w \cdot F dx &= \int_\Omega \nabla \cdot (p v) dx - \int_\Omega ( p \nabla \cdot (v)) dx - \int_\Omega q (\nabla \cdot u) dx  - \eta_\mu + \int_\Omega \gamma \nabla \cdot u \: \nabla \cdot v dx
\end{align}
This doesn't change the equation, thus should result in the same solution. However according to the same papers [2 \& 9] we can then approximate $S$ by the pressure mass matrix. We then perform ILU in order to solve for $S^{-1}$. ILU performs the Lu Factorization on various blocks of the matrix independently. This allows us to parallelize the process, reducing overall computing time by splitting the work onto multiple computing machines.\\
Note that in theory we could have tried a similar method in the CG space.
Testing shows however that this fails.
This makes sense as we utilized the exact divergence free-property of our space for the Schur complement.
As a result in the CG space as gamma tends to infinity S does not exactly tend to the pressure mass matrix.

\subsection{Steady Navier-Stokes}
We now have a discretization of the Stokes equation and an efficient Preconditioner for it.
Our aim is to solve the steady Navier Stokes equations, hence we will now include it, and thus get for the velocity equation :
\begin{align*}
(u \cdot \nabla) u &= -\nabla p + \mu \nabla^2 u + F
\end{align*}
Note that this is equation is not linear, hence we will need to use Newton's method.\\
We will first focus on finding the weak form of the advection term in order to add it to the previously obtained results. Testing however showed that this does not always converge due to the initial guess being outside of the Newton ball of convergence. Hence we will also build a continuation solver avoid that issue.

\subsubsection{Advection Weak Form}
In order to solve the equation, we need to find the weak form of the advection term, $(u \cdot \nabla) u$, which we will then add to the stokes weak form.\\
Similarly to before we therefore take the inner product of the advection term with $q$ and integrate over the domain.
\begin{align}
\int_\Omega (u \cdot \nabla)u \cdot v \ dx
\end{align}
Consider the following vector identity :
\begin{align*}
\nabla (u \cdot u) = 2 (u \cdot \nabla) u + 2 u \times (\nabla \times u)
\end{align*}
Hence get :
\begin{align}
\int_\Omega (u \cdot \nabla)u \cdot v \ dx = \frac{1}{2} \int_\Omega \nabla (u^2) \cdot v \ dx - \int_{\Omega} u \times (\nabla \times u) \cdot v \ dx
\end{align}
We can then perform an integration by parts on the first term on the right hand side to get :
\begin{align}
 \frac{1}{2} \int_\Omega \nabla (u^2) \cdot v \ dx = \frac{1}{2} (\int_{\delta \Omega } u^2 v \cdot n \ ds - \int_\Omega u^2 \nabla \cdot v \ dx)
\end{align}
Now consider the second term in (17)
\begin{align*}
- \int_{\Omega} u \times (\nabla \times u) \cdot v \ dx &= \int_{\Omega} v \cdot (\nabla \times u) u \ dx   \\
&=  \int_{\Omega} (\nabla \times u) \cdot (u \times v)  \ dx
\end{align*}
Next we use the results from source [18].\\
From this we obtain that via integration by parts on each individual element we get :
\begin{align*}
\sum_e \int_e u \cdot (\nabla \times (u \times v) \ ) dx - \int_{\Gamma} \frac{1}{2}(\{u\} + sgn(u \cdot n)[u]) \cdot (n \times (u \cdot v) \ ) dS
\end{align*}
Hence get :
\begin{align}
&\int_\Omega u \cdot (\nabla \times (u \times v) \ ) dx -  \sum_e \int_{\Gamma} u_{up} \cdot (n \times (u \cdot v) \ ) dS \\
& u_{up} = \frac{1}{2}((sgn(u \cdot n) + 1)_+ u_+ + (sgn (u \cdot n) +1)_- u_-)
\end{align}
$u_{up}$ is the upwinding term mentioned in the paper.\\
Note that it is equal to $u^+$ if $n$ is in the "positive" direction, and $u^-$ otherwise. (Reminder : the positive and negative direction are arbitrarily set when creating the mesh. They serve solely as markers for the software)\\
Note that the second term becomes the following on the computational domain boundary :
\begin{align*}
- \int_{\delta \Omega} u_0 \cdot (n \times (u \cdot v) \ ) ds
\end{align*}
Hence the weak form of our advection term is :
\begin{align}
 Adv &= \int_\Omega u \cdot (\nabla \times (u \times v) \ ) dx - \int_{\Gamma} u_{up} \cdot (n \times (u \cdot v) \ ) dS \\
&- \frac{1}{2} \int_\Omega u^2 \nabla \cdot v \ dx - \int_{\delta \Omega} u_0 \cdot (n \times (u \cdot v) \ ) ds
+ \frac{1}{2} \int_{\delta \Omega } u^2 v \cdot n \ ds
\end{align}
We reordered some terms to be in-line with our code.

\subsubsection{Continuation Method}

Given the Navier-Stokes equations we could try to naively solve directly applying the above preconditioning and discretization methods. However at high Reynolds number this approach quickly fails unless the mesh is refined or a better initial guess is given, leading to high computational cost or inability to solve certain problems.\\
Hence consider the modified equation :
\begin{align}
c (u \cdot \nabla) u &= -\nabla p + \mu \nabla^2 u + F
\end{align}
As mentioned in the Newton's Method section, the Newton's Method converges only if the initial guess is within a certain ball around the solution. Hence we need to find a method to get our initial guess to be closer to the solution.\\
We could use the stokes solution as an initial guess, which we can most likely solve. We then increase $c$ to $1$ and try to solve using the stokes solution as a guess. \\
If it still fails we can take $c =0.5$ before solving for full advection. If necessary we can bring down the value of $c$ multiple times until our solver converges at an appropriate rate. Afterwards we then gradually increase c using the same procedure until we solve for full advection.\\
In effect we are parametrizing the equation with $c$ and are gradually going from the simpler Stokes equation to the full Navier-Stokes equation, using the prior steps as initial guesses. This method, and similar algorithms, are described in [17].\\
\\
We can speed up this process in two ways.\\
The first, very simple method, is adapting our step-size to the problem. Rather than starting with a step size of $1$ we can reduce the step size initially if the Reynolds number is high enough. In addition to reducing the step size if the newton iteration fails, we can increase step size if it succeeds. This should allow us to close in on the optimal step size rapidly. This allows us to reduce the total number of times we try to use the Newton's method.\\
The second involves approximating the $(u,p)$ at a subsequent step more accurately. Rather than just using the prior value of $(u,p)$, call it $x_c$, we use Taylor expansion. We can consider $x_c$ to be a function of $c$, hence get :
$$
x_{c+\Delta c} = x_c + \Delta c \frac{\partial x_c}{\partial c}
$$
Provided we can find $\frac{\partial x_c}{\partial c}$ this will give us a far more accurate solution.
To find the derivative of $x_c$ with respect to $c$ we consider :\\

Which we solve via a newton iteration.\\
In some circumstances however even with a variable step-size in $c$ we fail to obtain a solution within an acceptable time-frame. In our code if the step-size is below $10^{-3}$ our solver stops and fails. This usually happens for high Reynolds number flows.

\subsection{Unsteady Navier-Stokes}

While we are mainly interested in the steady-state solution of the Navier-Stokes equation we also may want to consider whether or not the solution is stable. To that end we need to solve a full unsteady Navier-Stokes, including the time derivative. This will be used to determine if small perturbations of the solution die down or blow up.

\subsubsection{Time Stepping}
First we need to write an algorithm which can time-step on the unsteady Navier-Stokes equations.\\
In practice our problem amounts to the following, very generalized, equation :
\begin{align}
F(u) = 0
\end{align}
Where F is some function.\\
If we add in the time-terms we get :
\begin{align}
\frac{\partial u}{\partial t} + F(u,p) = 0
\end{align}
While we could try and solve this equation directly using Backwards Euler or Midpoint Rule along with a Newton iteration testing shows that this does not converge. Instead we use Picard's iteration along with the Midpoint rule as described in the following equation :
\begin{align}
u^{n+1} - u^n + \Delta t (\frac{1}{2}G(u^n,p^n) + \frac{1}{2} G(u^{n+1},p^{n+1}) + ( u^n \cdot \nabla u^n) ) = 0
\end{align}
Here $G = RHS - LHS $. We applied the midpoint rule to the linear terms of the equation while the non-linear term, the advection term, was evaluated at the previous time step. Provided the time step is low enough this will always converge, regardless of initial guess.\\
Optionally we could afterwards use the method we described first, Newton's method and Midpoint Rule, to get a more accurate result after a few Picard's iterations.
\begin{align}
u^{n+1} - u^n + \Delta t (\frac{1}{2}F(u^n,p^n) + \frac{1}{2} F(u^{n+1},p^{n+1})) = 0
\end{align}

\subsubsection{Stability Analysis}

When interested in the stability of a solution analytically we commonly first determine the solution. We would then consider the normal modes form of the equation before perturbing it. After some algebra we determine the most unstable mode and deduce from that.\\
While there are methods to determine these unstable modes numerically we will not use either of these methods here.\\
Instead we will use a far simpler algorithm.
We will consider random perturbations and then use the time stepping method above to see if they grow.

\section{Test Cases}
In this section we will consider various test cases to verify convergence of the algorithm at expected rates and demonstrate its ability to resolve various complex problems in complex non-uniform domains.
\subsection{Stokes Convergence}

Once again we will primarily focus on the stokes equation (9-10) in order to verify that this part of our discretization is working as intended.\\
We will consider a manufactured solution, an artificial solution we selected in advance. Take $u_x = sin(2 \pi y) cos(2 \pi y)*sin(2 \pi x)^2$, $u_y= -sin(2 \pi x) cos(2 \pi x) sin(2 \pi y)^2$ and $p = sin(2 \pi x) sin(2 \pi y)$.\\
We then adjust the boundary conditions and forcing term appropriately for this solution to hold.\\
 The forcing term thus becomes :$F = \nabla p - \mu \nabla^2 u$.\\
Figures and show us the convergence graphs in velocity and pressure.\\
This shows that the preconditioning and discretization holds as expected for the stokes equation if boundary conditions are $0$.
\\

\begin{figure}
  \includegraphics[width=\linewidth]{stokes_convergence_dbc0.png}
  \caption{DG2-BDM1 Stokes velocity convergence plot of velocity error against resolution. As expected the velocity error decreases with a logarithimic slope of rougly 2, indicating order 2 convergence as expected.}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{stokes_pressure_convergence_dbc0.png}
  \caption{DG2-BDM1 Stokes pressure convergence plot of pressure error against resolution. As expected the pressure error decreases with a logarithimic slope of rougly 2, indicating order 2 convergence as expected.}
\end{figure}

\subsection{Navier-Stokes Convergence}

We again use a manufactured solution to determine the convergence rate of our solver.
We can re-use the first solution in the stokes convergence test, $u_x = sin(2 \pi y) cos(2 \pi y)sin(2 \pi x)^2$, $u_y= -sin(2 \pi x) cos(2 \pi x) sin(2 \pi y)^2$ and $p = sin(2 \pi x)^2 sin(2 \pi y)^2$.\\
However the forcing term will now be $F = \nabla p - \mu \nabla^2 u + u \cdot \nabla u$.
Plugging this into the equations we get that these do indeed solve the Navier-Stokes equations.\\
Figures and show us the convergence graphs in velocity and pressure.\\

\begin{figure}
  \includegraphics[width=\linewidth]{navier_stokes_convergence_dbc0.png}
  \caption{DG2-BDM1 Navier-Stokes velocity convergence plot of velocity error against resolution. As expected the velocity error decreases with a logarithmic slope of roughly 2, indicating order 2 convergence as expected. We used the direct solver, not applying the continuation solver.}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{navier_stokes_pressure_convergence_dbc0.png}
  \caption{DG2-BDM1 Stokes pressure convergence plot of pressure error against resolution. As expected the pressure error decreases with a logarithmic slope of roughly 2, indicating order 2 convergence as expected. We used the direct solver, not applying the continuation solver.}
\end{figure}

\subsection{Flow Between Concentric Circles}

We will study this relatively simple problem as means to demonstrate the ability of our solver to work even on non-uniform arbitrary meshes and solve an unsteady problem.\\
The problem takes place in the annulus between two concentric circles each rotating at a different speed. For our steady case we will consider unit circle rotating at speed $1$ and circle of radius $2$ rotating at speed $3$.
From [16] we get that the general solution of the tangential velocity and pressure for this problem is of the form :
\begin{align}
u_{\phi} = C_1 r + \frac{C_2}{r} \\
p = \rho \int \frac{u_{\phi}^2}{r} dr + C
\end{align}
From the above boundary conditions are $u_{\phi}(r=1) = 1$, $u_{\phi}(r=2) = 3$. Hence get :
\begin{align*}
C_1 = 1 - C_2
\end{align*}
Figures show pressure and velocity in this case.\\

Now consider the outer circle initially immobile, but slowly accelerating until it reaches tangential speed of $3$. The velocity solution at different time steps is shown in figures.

\subsection{Flow Past a Cylinder}

The flow past a cylinder is a well-known and studied flow with interesting properties, namely in stability of its steady solution.\\
Hence we will see how our solver resolves this flow and compare results with other papers [14].\\

Figure shows the stokes solution to the problem.\\
Similarly figures to show the solution with full advection at Reynolds numbers respectively.\\
At Reynolds numbers higher than our solver starts requiring to use the continuation method multiple times (by default it always first finds the stokes solution). Eventually it the length of the continuation step goes below tolerance levels and our solver fails.\\
However according to sources this corresponds to the Reynolds numbers where the solution becomes unstable.\\
We reduce the Reynold's number by reducing the viscosity. As expected this makes the boundary layer about the cylinder smaller and smaller. Note that we also needed to refine mesh during this process. Likely due to the critical velocity fluctuations on smaller and smaller scales about the cylinder.

\subsection{Cylinder flow Stability}

\section{Conclusion and Future Improvements}

In this project we were interested in applications of the BDM/DG mixed finite element onto the steady Navier-Stokes equations.\\
After briefly discussing the general finite element method and some introductory definitions and notations we decided to focus on the stokes equation. After assembling the weak form of the equation we then applied a Schur preconditioner to  improve efficiency.\\
We then assembled a weak form of the Navier-Stokes equation but noted that directly using it wasn't optimal. As such we developed a continuation method with variable step-size to improve the algorithm's speed and expand the number of problems which it can solve.\\
After this we made a rudimentary time-stepping method to study the stability of any solutions obtained.\\
Finally we tested all of the above and concluded that our algorithm worked as anticipated.\\
\\
\\
However a number of future improvements could be made.
These would allow us to reduce computational cost, versatility and accuracy of our method.\\
\\
We could use a multigrid method using our method as a smoother to get convergence to be less dependent on grid-size, dramatically reducing computational costs. Application of such a method was discussed, unfortunately the tools required for it are not currently compatible with our problem set (specifically dirichelet boundary conditions).\\
The variable step-size method is serviceable and can be considerably improved to reduce the total number of iterations and thus computational cost. There are a number of methods which from local conditions of the function could more efficiently determine an appropriate step-size. Our source on the continuation method [17] includes such improvements.\\
Similarly the time-stepping method was designed exclusively for the stability test. For this purpose it works very well. However various improvements could be made for accuracy and speed. For instance we initially attempted to utilise a Newton iteration rather than a Picards iteration. However as the initial guess wasn't in the ball of convergence this method failed. Adding a few Newton iterations using the picards results as a starting point should give more accurate answers for time-dependent methods.\\
Additionally the stability itself could be expanded to for instance consider the growth rate of an instability as well as determines unstable modes.\\
In some flows we may have multiple solutions or a bifurcation (that is the case for the cylinder flow at high Reynolds number). In this case a deflation method may be usefull. In this method, after finding a solution we "substract" it from the equation and thus seek other solutions.\\
\\


\section{Appendix}
\subsection{Discussing the Code}
A significant part of this project was developing a python code using firedrake.
Firedrake is a python project which aims to provide mathematicians, engineers and scientists with an automated system for solving partial differential equations.\\
It does so by automatically generating code based on UFL expressions from the fenics project, a library of computational methods used for solving PDEs. This allows us to write out our equations in a fairly intuitive way while firedrake generates the background code needed to solve them.\\
Our project comprises largely of one file containing the rinsp and rinspt classes, though various launching scripts and the Lagrange script are also present. We will not discuss the entirety of either class, if the reader wants to have a detailed look he can go to the github repository containg it at https://github.com/Frostyant/M4R\_Navier\_Stokes\_Solvers once it has been made public.\\
We will however show a handful of code snippets, ranging from the parameters firedrake uses to the generate the code to the ufl expressions for the viscous, pressure and advection terms.

\subsubsection{Solver Paremeters}
The parameters of our solver are :
\begin{lstlisting}
"ksp_type": "gmres",
            "ksp_converged_reason": True,
            "ksp_rtol": 1e-6,
            "ksp_max_it": 50,
            "pc_type": "fieldsplit",
            "pc_fieldsplit_type": "schur", #use Schur preconditioner
            "pc_fieldsplit_schur_fact_type": "full", #full preconditioner
            "pc_fieldsplit_off_diag_use_amat": True,
            "fieldsplit_0_ksp_type": "preonly",
            "fieldsplit_0_pc_type": "lu",#use full LU factorization, ilu fails
            "fieldsplit_0_pc_factor_mat_solver_type": "mumps",
            "fieldsplit_1_ksp_type": "preonly",
            "fieldsplit_1_pc_type": "bjacobi",
            "fieldsplit_1_pc_sub_type": "ilu"#use incomplete LU factorization on the submatrix
\end{lstlisting}
GMRES indicates the solver used for the outer system.
 It stands for generalized minimal residual method, and used due to nonsymmetric nature of our equation.\\
ksp\_rtol indicates the relative tolerance above which we consider that the equation diverges.\\
ksp\_max\_it is the maximal number of iterations for the linear GMRES solver. If above it the solver fails or, in the continuation method, reduces the advection term and tries again.\\
"pc\_type": "fieldsplit" tells the algorithm that the matrix has a block structure as describe in the Schur preconditioner section.\\
"pc\_fieldsplit\_type": "schur" indicates we are using the Schur fieldsplit preconditioner.\\
"pc\_fieldsplit\_off\_diag\_use\_amat": True indicates that the offdiagonal terms, ie the $B$ and $B^T$ described in section 3.1.2 \\
"fieldsplit\_0 options deal with finding $A^{-1}$ in the Schur Preconditioner while the fieldsplit\_1 options deal with the remaining part of the preconditioner.\\

\subsubsection{Advection Term}
The ufl plugin allows us to write out our weak equations almost directly into code. Pieces of code can thus be deduced directly from the weak forms determined in sections 3.1.1, 3.2.1 and 3.3.1. We display the advection term here both to display an example as well as to discuss some specifics when dealing with 2D problems.\\
the code associated to the advection term is :
\begin{lstlisting}
def GetAdvectionTerm(self,up,InflowBc,Bcs):

        n = FacetNormal(self.mesh)
        #splitting u and p for programming purposes (unavoidable)
        u, p = split(up)

        #Re-Defining functions for use in Advection term
        if self.twoD:
            curl = lambda phi: as_vector([-phi.dx(1), phi.dx(0)])
            cross = lambda u, w: -u[1]*w[0]+u[0]*w[1]
            perp = lambda n, phi: as_vector([n[1]*phi, -n[0]*phi])
        else:
            perp = cross

        #Defining upwind and U_upwind for use in advection
        Upwind = 0.5*(sign(dot(u, n))+1)
        U_upwind = Upwind('+')*u('+') + Upwind('-')*u('-')

        #Assembling Advection Term
        adv_byparts1 = inner(u, curl(cross(u, self.v)))*dx 
	#This is the term from integration by parts of double curl
        adv_byparts2 = inner(U_upwind, 2*avg( perp(n, cross(u, self.v))))*dS 
	#Second term over surface
        adv_grad_parts1 = 0.5*div(self.v)*inner(u,u)*dx 
	#This is the term due to the integration by parts of grad u^2
        if not InflowBc:
            adv_bdc1 = inner(u,perp(n,cross(u,self.v)))*ds(Bcs) 
	#boundary version of adv_byparts2
            adv_grad_parts2 = 1/2*inner(inner(u,u)*self.v,n)*ds(Bcs) 
	#boundary term from grad u^2 integration by parts
        else:
            adv_bdc1 = inner(u,perp(n,cross(u,self.v)))*ds(Bcs) 
	#boundary version of adv_byparts2
            adv_grad_parts2 = 1/2*inner(inner(u,u)*self.v,n)*ds(Bcs) 
	#boundary term from grad u^2 integration by parts
            adv_bdc1 +=  inner(self.u_0,perp(n,cross(self.u_0,self.v)))*ds(InflowBc) 
	#boundary version of adv_byparts2
            adv_grad_parts2 += 1/2*inner(inner(self.u_0,self.u_0)*self.v,n)*ds(InflowBc) 
	#boundary term from grad u^2 integration by parts

        advection_term = (
            adv_byparts1
            - adv_byparts2
            - adv_grad_parts1
            - adv_bdc1
            + adv_grad_parts2
        )

        return advection_term
\end{lstlisting}
Note that inflow boundary conditions have to be treated separately from no-slip boundary conditions.\\
Additionally note that we had to specify a special case for 2D. While most of the ufl code works in 2D and 3D in the same way, the cross product is ill defined purely in 2D. Hence we needed to define special operiations for each possible instance of the cross product.\\

\subsection{Selecting the Manufactured Solution}
The method of manufactured solution, which we used multiple times to determine the accuracy and rate of convergence of the various computational methods discussed. While the method primarily involves artificially creating a solution to the equation by adjusting the forcing term some though has to be put into selecting the solution. Otherwise we may find that the algorithms do not converge.\\ 
Firstly any manufactured solution needs to actually solve the equations. For simplicity we eliminate the continuity equation by considering the stream function rather than the velocity field. Where the stream function is defined is :
\begin{align*}
\frac{ \partial \psi}{\partial y} = u_x \\
-\frac{\partial \psi}{\partial x} = u_y
\end{align*}
When selecting the manufactured solution we want one which is preferably as simple as possible and easy to check. For instance we always started with $0$ boundary conditions in velocity. This both made determining errors on the boundaries easy and avoided a lot of the issues that come with outflows and inflows for the navier stokes equations. For the streamfunction this implies that the derivatives are 0 at the boundaries. We can easily resolve this by setting $\psi = sin(2 \pi x)^n sin(2 \pi y)^n$ with n greater than 2.\\
Another thing to consider is the pressure conditions. We technically did not force any, but the equation naturally has them. Consider dotting the Navier-Stokes equations with the normal at the boundaries :
\begin{align*}
\nabla p \cdot n &= -(u \cdot \nabla) u \cdot n  + \mu \nabla^2 u \cdot n + F \cdot n \\
x \in \delta \Omega
\end{align*}
Thus the Dirichelet normal boundary conditions imply conditions on $\frac{\partial p}{\partial n}$.\\
For simplicity we want this to be $0$ too.\\
Note how every term on the left-hand side is either proportional to $\psi$, one of its derivatives or a sum of those. Hence all these terms become $0$ at all the boundaries if $n$ is large enough (as we would have $ sin(2 \pi x) sin(2 \pi y$ terms).\\
This can be verified, as when failing to get a large enough $n$ and attempting to solve for the $0$ pressure solution we will get a trigonometric structure on the boundaries in the pressure error as seen in figure.\\
As for setting the pressure, we need to ensure that $\frac{\partial p} {\partial n} = 0$, using a similar method to above we can consider $p =  sin(2 \pi x)^2 sin(2 \pi y)^2$.\\
Hence we get our standard manufactured solution :
\begin{align}
u_x = sin(2 \pi y)^3 cos(2 \pi y)sin(2 \pi x)^4 \\
u_y= -sin(2 \pi x)^3 cos(2 \pi x) sin(2 \pi y)^4 \\
p = sin(2 \pi x)^2 sin(2 \pi y)^2
\end{align}
\section{Citations}

[1] Imperial College London \textit{Firedrake Project} Available from : https://www.firedrakeproject.org [Accessed througout 2018-2019]\\

[2] Patrick E. Farrell, Lawrence Mitchell, Florian Wechsung
 An Augmented Lagrangian Preconditioner For The 3D Stationary Incompressible Navier–Stokes Equation At High Reynolds Number
\textit{SIAM J. Sci Comput 28(6)}2006\\

[3] Arnold, Douglas N., et al. "Unified analysis of discontinuous Galerkin methods for elliptic problems." SIAM journal on numerical analysis 39.5 (2002): 1749-1779.\\

[4] Vassilevski, Panayot S. Multilevel Block Factorization Preconditioners: Matrix-based Analysis and Algorithms for Solving Finite Element Equations. New York, NY: Springer New York, 2008. Web.\\

[5] Ibrahimbegovic, Adnan. \textit{Nonlinear Solid Mechanics}. Vol. 160. Dordrecht: Springer Netherlands, 2009. Solid Mechanics and Its Applications. Web.\\

[6] Thomée, Vidar. (1986). \textit{Galerkin finite element methods for parabolic problems}. SERBIULA (sistema Librum 2.0). 25. 10.1007/978-3-662-03359-3. \\

[7]  Kirby R.C., Logg A., Rognes M.E., Terrel A.R. (2012) \textit{Common and unusual finite elements}. In: Logg A., Mardal KA., Wells G. (eds) Automated Solution of Differential Equations by the Finite Element Method. Lecture Notes in Computational Science and Engineering, vol 84. Springer, Berlin, Heidelberg\\

[8] Hansbo, Peter \& Larson, Mats. (2003). \textit{Discontinuous Galerkin and the Crouzeix–Raviart element: Application to elasticity}. http://dx.doi.org/10.1051/m2an:2003020. 37. 10.1051/m2an:2003020. \\

[9] Olshanskii, Maxim \& Reusken, Arnold. (2004). \textit{Grad-div stabilization for Stokes equations}. Mathematics of Computation - Math. Comput.. 73. 1699-1718. \\

[10] Huan Zhengda, \textit{The convergence ball of Newton's method and the uniqueness ball of equations under Hölder-type continuous derivatives},
Computers \& Mathematics with Applications,
Volume 47, Issues 2–3,
2004,
Pages 247-251,
ISSN 0898-1221,
https://doi.org/10.1016/S0898-1221(04)90021-1.\\

[11] X Wang, \textit{Convergence of Newton's method and uniqueness of the solution of equations in Banach space}, IMA Journal of Numerical Analysis, Volume 20, Issue 1, January 2000, Pages 123–134, https://doi.org/10.1093/imanum/20.1.123\\

[12] Bae, Jong Sook, and Sangsuk Yie. \textit{Range of Gateaux Differentiable Operators and Local Expansions}  Pacific J. Math. 125.2 (1986): 289-300. Web.\\

[13] Zi-Cai Li, Cheng-Sheng Chien, Hung-Tsai Huang,\textit{
Effective condition number for finite difference method},
Journal of Computational and Applied Mathematics,
Volume 198, Issue 1,
2007,
Pages 208-235,
ISSN 0377-0427,
https://doi.org/10.1016/j.cam.2005.11.037.\\

[14] Hashiguchi, Masanori \& Kuwahara, Kunio. (1996). \textit{Two-Dimensional Study of Flow past a Circular Cylinder}. RIMS Kokyuroku. 974. \\

[15] Cockburn B, Kanschat G, Schötzau D. \textit{A note on discontinuous galerkin divergence-free solutions of the navier-stokes equations. Journal of Scientific Computing}. 2007 Jun 1;31(1-2):61-73. https://doi.org/10.1007/s10915-006-9107-7\\

[16] Constantinescu V.N. (1995) \textit{Other Solutions of Navier-Stokes Equations (Steady Incompressible Flow).} In: Laminar Viscous Flow. Mechanical Engineering Series. Springer, New York, NY\\

[17] Deuflhard P. (2011) Parameter Dependent Systems: Continuation Methods. In: \textit{Newton Methods for Nonlinear Problems}. Springer Series in Computational Mathematics, vol 35. Springer, Berlin, Heidelberg\\

[18] Natale, Andrea, and Colin J. Cotter. \textit{Scale‐selective Dissipation in Energy‐conserving Finite‐element Schemes for Two‐dimensional Turbulence}  Quarterly Journal of the Royal Meteorological Society 143.705 (2017): 1734-745. Web.\\



\end{document}
